{
  "decoratorName": "Abductive",
  "version": "1.0.0",
  "description": "Structures the response using abductive reasoning, developing the most likely explanations for observations or phenomena. This decorator emphasizes inference to the best explanation and hypothetical reasoning to address incomplete information.",
  "author": {
    "name": "Prompt Decorators Working Group",
    "email": "promptdecoratorspec@synapti.ai",
    "url": "https://synapti.ai"
  },
  "parameters": [
    {
      "name": "hypotheses",
      "type": "number",
      "description": "Number of alternative hypotheses or explanations to generate",
      "default": 3,
      "required": false,
      "validation": {
        "minimum": 2,
        "maximum": 5
      }
    },
    {
      "name": "criteria",
      "type": "array",
      "description": "Specific criteria to evaluate hypotheses against (e.g., simplicity, explanatory power)",
      "required": false
    },
    {
      "name": "rank",
      "type": "boolean",
      "description": "Whether to explicitly rank hypotheses by likelihood",
      "default": true,
      "required": false
    }
  ],
  "examples": [
    {
      "description": "Basic abductive reasoning with multiple hypotheses",
      "usage": "+++Abductive\nWhy have bee populations been declining globally?",
      "result": "Presents observed facts about bee population decline, generates three possible explanations, and identifies the most likely causes based on available evidence"
    },
    {
      "description": "Detailed abductive reasoning with specific evaluation criteria",
      "usage": "+++Abductive(hypotheses=4, criteria=[comprehensiveness,simplicity,novelty,testability], rank=true)\nWhat might explain the Fermi Paradox?",
      "result": "Develops four hypotheses explaining the Fermi Paradox, evaluates each against the specified criteria, and ranks them from most to least likely explanation"
    }
  ],
  "compatibility": {
    "requires": [],
    "conflicts": [],
    "minStandardVersion": "1.0.0",
    "maxStandardVersion": "2.0.0",
    "models": [
      "gpt-4",
      "gpt-3.5-turbo"
    ]
  }
} 